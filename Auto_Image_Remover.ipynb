{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayushJkumar/Auto_Img_Bg_Remover_MODNet/blob/main/Auto_Image_Remover.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiOCyywgy_ZQ"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLpKAyo0zcgc",
        "outputId": "6e158d24-d36d-4183-efb4-df00f6bf90cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/MODNet\n"
          ]
        }
      ],
      "source": [
        "# clone the repository\n",
        "%cd /content\n",
        "if not os.path.exists('MODNet'):\n",
        "  !git clone https://github.com/ZHKKKe/MODNet\n",
        "%cd MODNet/\n",
        "\n",
        "# dowload the pre-trained ckpt for image matting\n",
        "pretrained_ckpt = 'pretrained/modnet_photographic_portrait_matting.ckpt'\n",
        "if not os.path.exists(pretrained_ckpt):\n",
        "  !gdown --id 1mcr7ALciuAsHCpLnrtG_eop5-EYhbCmz \\\n",
        "          -O pretrained/modnet_photographic_portrait_matting.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkBL5wUL0ZOl"
      },
      "outputs": [],
      "source": [
        "# clean and rebuild the image folders\n",
        "input_folder = 'demo/image_matting/colab/input'\n",
        "if os.path.exists(input_folder):\n",
        "  shutil.rmtree(input_folder)\n",
        "os.makedirs(input_folder)\n",
        "\n",
        "output_folder = 'demo/image_matting/colab/output'\n",
        "if os.path.exists(output_folder):\n",
        "  shutil.rmtree(output_folder)\n",
        "os.makedirs(output_folder)\n",
        "image_names = os.listdir('/content/drive/MyDrive/IIT GUWAHATI Internship Task TASK/Frontal Images')\n",
        "for i in image_names :\n",
        "  shutil.move(os.path.join('/content/drive/MyDrive/IIT GUWAHATI Internship Task TASK/Frontal Images',i), os.path.join(input_folder,i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV6YSrbX4IlK",
        "outputId": "6cc072de-046d-4834-a531-16cf34d70477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process image: 000073.jpg\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3680: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "Process image: 000003.jpg\n",
            "Process image: 000010.jpg\n",
            "Process image: 000088.jpg\n",
            "Process image: 000072.jpg\n",
            "Process image: 000052.jpg\n",
            "Process image: 000029.jpg\n",
            "Process image: 000050.jpg\n",
            "Process image: 000076.jpg\n",
            "Process image: 000023.jpg\n",
            "Process image: 000078.jpg\n",
            "Process image: 000046.jpg\n",
            "Process image: 000063.jpg\n",
            "Process image: 000004.jpg\n",
            "Process image: 000082.jpg\n",
            "Process image: 000091.jpg\n",
            "Process image: 000031.jpg\n",
            "Process image: 000069.jpg\n",
            "Process image: 000045.jpg\n",
            "Process image: 000079.jpg\n",
            "Process image: 000061.jpg\n",
            "Process image: 000016.jpg\n",
            "Process image: 000090.jpg\n",
            "Process image: 000068.jpg\n",
            "Process image: 000071.jpg\n",
            "Process image: 000047.jpg\n",
            "Process image: 000055.jpg\n",
            "Process image: 000089.jpg\n",
            "Process image: 000040.jpg\n",
            "Process image: 000075.jpg\n",
            "Process image: 000060.jpg\n",
            "Process image: 000028.jpg\n",
            "Process image: 000018.jpg\n",
            "Process image: 000042.jpg\n",
            "Process image: 000020.jpg\n",
            "Process image: 000035.jpg\n",
            "Process image: 000049.jpg\n",
            "Process image: 000064.jpg\n",
            "Process image: 000081.jpg\n",
            "Process image: 000043.jpg\n",
            "Process image: 000085.jpg\n",
            "Process image: 000095.jpg\n",
            "Process image: 000051.jpg\n",
            "Process image: 000084.jpg\n",
            "Process image: 000077.jpg\n",
            "Process image: 000006.jpg\n",
            "Process image: 000032.jpg\n",
            "Process image: 000015.jpg\n",
            "Process image: 000027.jpg\n",
            "Process image: 000083.jpg\n",
            "Process image: 000001.jpg\n",
            "Process image: 000048.jpg\n",
            "Process image: 000022.jpg\n",
            "Process image: 000059.jpg\n",
            "Process image: 000087.jpg\n",
            "Process image: 000037.jpg\n",
            "Process image: 000067.jpg\n",
            "Process image: 000066.jpg\n",
            "Process image: 000033.jpg\n",
            "Process image: 000034.jpg\n",
            "Process image: 000009.jpg\n",
            "Process image: 000070.jpg\n",
            "Process image: 000038.jpg\n",
            "Process image: 000057.jpg\n",
            "Process image: 000024.jpg\n",
            "Process image: 000025.jpg\n",
            "Process image: 000053.jpg\n",
            "Process image: 000093.jpg\n",
            "Process image: 000065.jpg\n",
            "Process image: 000026.jpg\n",
            "Process image: 000036.jpg\n",
            "Process image: 000092.jpg\n",
            "Process image: 000094.jpg\n",
            "Process image: 000058.jpg\n",
            "Process image: 000039.jpg\n",
            "Process image: 000008.jpg\n",
            "Process image: 000080.jpg\n",
            "Process image: 000062.jpg\n",
            "Process image: 000041.jpg\n",
            "Process image: 000074.jpg\n",
            "Process image: 000086.jpg\n",
            "Process image: 000056.jpg\n",
            "Process image: 000030.jpg\n",
            "Process image: 000017.jpg\n",
            "Process image: 000054.jpg\n"
          ]
        }
      ],
      "source": [
        "!python -m demo.image_matting.colab.inference \\\n",
        "        --input-path demo/image_matting/colab/input \\\n",
        "        --output-path demo/image_matting/colab/output \\\n",
        "        --ckpt-path ./pretrained/modnet_photographic_portrait_matting.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vfw_9Uvx9W6y",
        "outputId": "10df8ae0-733a-4b12-e985-6f0699e62c05"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "c=1\n",
        "def combined_display(image, matte,name):\n",
        "  # calculate display resolution\n",
        "  w, h = image.width, image.height\n",
        "  rw, rh = 800, int(h * 800 / (3 * w))\n",
        "  \n",
        "  # obtain predicted foreground\n",
        "  image = np.asarray(image)\n",
        "  if len(image.shape) == 2:\n",
        "    image = image[:, :, None]\n",
        "  if image.shape[2] == 1:\n",
        "    image = np.repeat(image, 3, axis=2)\n",
        "  elif image.shape[2] == 4:\n",
        "    image = image[:, :, 0:3]\n",
        "  matte = np.repeat(np.asarray(matte)[:, :, None], 3, axis=2) / 255\n",
        "  foreground = image * matte + np.full(image.shape, 255) * (1 - matte)\n",
        "  \n",
        "  # combine image, foreground, and alpha into one line\n",
        "  # combined = np.concatenate((image, foreground, matte * 255), axis=1)\n",
        "  # combined = Image.fromarray(np.uint8(combined)).resize((rw, rh))\n",
        "  # combined = Image.fromarray(np.uint8(foreground)).resize((rw, rh))\n",
        "  combined = Image.fromarray(np.uint8(foreground)).resize((w,h))\n",
        "  # s=name\n",
        "  # combined.save(os.path.join('/content/drive/MyDrive/IIT GUWAHATI Internship Task TASK/Frontal_Images_output',name))\n",
        "  \n",
        "  return combined\n",
        "\n",
        "# visualize all images\n",
        "image_names = os.listdir(input_folder)\n",
        "for image_name in image_names:\n",
        "  matte_name = image_name.split('.')[0] + '.png'\n",
        "  image = Image.open(os.path.join(input_folder, image_name))\n",
        "  matte = Image.open(os.path.join(output_folder, matte_name))\n",
        "  display(combined_display(image, matte,image_name))\n",
        "  combined_display(image, matte,image_name).save('/content/drive/MyDrive/IIT GUWAHATI Internship Task TASK/IMg_Bg_Removed'+'/'+ image_name)\n",
        "  print(image_name, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5erKoJKO-EKs"
      },
      "outputs": [],
      "source": [
        "# zip_filename = 'matte.zip'\n",
        "# if os.path.exists(zip_filename):\n",
        "#   os.remove(zip_filename)\n",
        "\n",
        "# os.system(f\"zip -r -j {zip_filename} {output_folder}/*\")\n",
        "# files.download(zip_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1slZ3o-_4Pg"
      },
      "outputs": [],
      "source": [
        "# image_names = os.listdir(input_folder)\n",
        "# for i in image_names :\n",
        "#     cur_image_path = os.path.join(input_folder,i)\n",
        "#     cur_image_out_path = os.path.join('/content/drive/MyDrive/IIT GUWAHATI Internship Task TASK/Frontal_Images_output',i)\n",
        "#     shutil.copyfile(cur_image_path, cur_image_out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6REAArJFufK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Auto_Image_Remover",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}